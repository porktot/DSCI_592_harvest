{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCSI 592: Capstone II\n",
    "\n",
    "## Predicting Crop Yield in Colorado: Modeling\n",
    "\n",
    "Dataset: https://catalog.data.gov/dataset/usda-ars-colorado-maize-water-productivity-dataset-2012-2013-f9f68\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Imports, Helper Functions & Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply log transformation and add a constant to deal with 0s\n",
    "def apply_log_transform_with_constant(dataframe, constant=1e-5):\n",
    "    # Copy the input dataframe to avoid modifying the original data\n",
    "    transformed_df = dataframe.copy()\n",
    "        # Apply logarithmic transformation to numeric columns\n",
    "    for col in transformed_df.select_dtypes(include=['number']).columns:\n",
    "        # Add a small constant value to avoid zero values\n",
    "        transformed_df[col] = np.log(transformed_df[col] + constant)\n",
    "    return transformed_df\n",
    "\n",
    "# organizes and neatly displays model results for model evaluation\n",
    "def display_model_results(train_mse, train_r2, test_mse, test_r2, cross_val_rmse, cross_val_r2, model_description):\n",
    "    print(f\"Results for {model_description.upper()}:\")\n",
    "    print(f\"Training MSE: {train_mse:.4f}\")\n",
    "    print(f\"Training R^2: {train_r2:.4f}\")\n",
    "    print(f\"Test MSE: {test_mse:.4f}\")\n",
    "    print(f\"Test R^2: {test_r2:.4f}\")\n",
    "    print(f\"Cross-Validation RMSE: {cross_val_rmse.mean():.4f} ± {cross_val_rmse.std():.4f}\")\n",
    "    print(f\"Cross-Validation R^2: {cross_val_r2.mean():.4f} ± {cross_val_r2.std():.4f}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "\n",
    "# applies pipeline (feature scaling), desired algorithm, cross validation method, and evaluates performance\n",
    "def evaluate_pipeline(pipeline, X_train, y_train, X_test, y_test, model_description, cv):\n",
    "    # train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # calculate training MSE and R^2\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Calculate test MSE and R^2\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # perform cross validation on training set\n",
    "    cross_val_mse = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "    cross_val_rmse = np.sqrt(-cross_val_mse)\n",
    "    \n",
    "    # cross validation R^2 score\n",
    "    cross_val_r2 = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='r2')\n",
    "    \n",
    "    # display model results using `display_model_results()` \n",
    "    display_model_results(train_mse, train_r2, test_mse, test_r2, cross_val_rmse, cross_val_r2, model_description)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94 entries, 0 to 93\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Grain Yield_15.5%mc_Kg ha-1  94 non-null     float64\n",
      " 1   Max_LAI                      94 non-null     float64\n",
      " 2   Annual_ETc mm                94 non-null     float64\n",
      " 3   Trt_code                     94 non-null     int64  \n",
      " 4   Plant density plants ha-1    94 non-null     float64\n",
      " 5   HI                           94 non-null     float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 4.5 KB\n"
     ]
    }
   ],
   "source": [
    "FILE = 'cleaned_annual_data.csv'\n",
    "maize_data = pd.read_csv(FILE)\n",
    "maize_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model, we will predict `grain yield` using: \n",
    "- irrigation `treatment code` (numerical value that represents the watering deprivation treatment used: the lower value treatments (1, 2, 3...) received more water, while higher values (9, 10, 11...) got less during both periods.Table in appendix)\n",
    "- `plant density`\n",
    "- `max leaf area index`\n",
    "\n",
    "Concept: if a farmer was facing a drought (limited water supply), could they use a model to optimize their watering and still achieve grain yield goals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94 entries, 0 to 93\n",
      "Data columns (total 4 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Grain Yield_15.5%mc_Kg ha-1  94 non-null     float64\n",
      " 1   Trt_code                     94 non-null     int64  \n",
      " 2   Plant density plants ha-1    94 non-null     float64\n",
      " 3   Max_LAI                      94 non-null     float64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 3.1 KB\n"
     ]
    }
   ],
   "source": [
    "# corrected variable name \n",
    "cols_for_model = [\"Grain Yield_15.5%mc_Kg ha-1\", \"Trt_code\",\"Plant density plants ha-1\", \"Max_LAI\"]\n",
    "maize_model_data = maize_data[cols_for_model]\n",
    "maize_model_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grain Yield_15.5%mc_Kg ha-1</th>\n",
       "      <th>Trt_code</th>\n",
       "      <th>Plant density plants ha-1</th>\n",
       "      <th>Max_LAI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.744325</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>11.343192</td>\n",
       "      <td>1.489657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.750410</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>11.288274</td>\n",
       "      <td>1.575948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.565569</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>11.265414</td>\n",
       "      <td>1.461266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.578622</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>11.258034</td>\n",
       "      <td>1.429405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.429054</td>\n",
       "      <td>0.693152</td>\n",
       "      <td>11.287757</td>\n",
       "      <td>1.646937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grain Yield_15.5%mc_Kg ha-1  Trt_code  Plant density plants ha-1   Max_LAI\n",
       "0                     9.744325  0.000010                  11.343192  1.489657\n",
       "1                     9.750410  0.000010                  11.288274  1.575948\n",
       "2                     9.565569  0.000010                  11.265414  1.461266\n",
       "3                     9.578622  0.000010                  11.258034  1.429405\n",
       "4                     9.429054  0.693152                  11.287757  1.646937"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_transformed_model_data = apply_log_transform_with_constant(maize_model_data)\n",
    "log_transformed_model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## 1. Linear Regression Results\n",
    "### 1.0 Linear Regression: Baseline (no scaling/no log transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LINEAR REGRESSION (NO SCALING / NO LOG TRANSFORMATION):\n",
      "Training MSE: 2184176.2584\n",
      "Training R^2: 0.3909\n",
      "Test MSE: 3737592.9884\n",
      "Test R^2: 0.3870\n",
      "Cross-Validation RMSE: 1547.5232 ± 265.7279\n",
      "Cross-Validation R^2: 0.2609 ± 0.2117\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Define features as `X` and target variable (Grain Yield) as `y`\n",
    "X = maize_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = maize_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize the model\n",
    "linear_regression_model = LinearRegression()\n",
    "\n",
    "# train the model on non-transformed data\n",
    "linear_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# calculate training MSE and R^2\n",
    "y_train_pred = linear_regression_model.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# calculate test MSE and R^2\n",
    "y_test_pred = linear_regression_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "cross_val_mse = cross_val_score(linear_regression_model, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "cross_val_rmse = np.sqrt(-cross_val_mse)\n",
    "\n",
    "# Perform cross-validation for R^2 score\n",
    "cross_val_r2 = cross_val_score(linear_regression_model, X_train, y_train, cv=cv, scoring='r2')\n",
    "\n",
    "# Display the results\n",
    "display_model_results(train_mse, train_r2, test_mse, test_r2, cross_val_rmse, cross_val_r2, model_description=\"Linear Regression (No Scaling / No Log Transformation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LINEAR REGRESSION (LOG TRANSFORMED / NO SCALING):\n",
      "Training MSE: 0.0159\n",
      "Training R^2: 0.3242\n",
      "Test MSE: 0.0234\n",
      "Test R^2: 0.3933\n",
      "Cross-Validation RMSE: 0.1319 ± 0.0262\n",
      "Cross-Validation R^2: 0.1849 ± 0.2005\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Define features as `X` and target variable (Grain Yield) as `y`\n",
    "X = log_transformed_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = log_transformed_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize the model\n",
    "linear_regression_model = LinearRegression()\n",
    "\n",
    "# train the model on non-transformed data\n",
    "linear_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# calculate training MSE and R^2\n",
    "y_train_pred = linear_regression_model.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# calculate test MSE and R^2\n",
    "y_test_pred = linear_regression_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "cross_val_mse = cross_val_score(linear_regression_model, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "cross_val_rmse = np.sqrt(-cross_val_mse)\n",
    "\n",
    "# Perform cross-validation for R^2 score\n",
    "cross_val_r2 = cross_val_score(linear_regression_model, X_train, y_train, cv=cv, scoring='r2')\n",
    "\n",
    "# Display the results\n",
    "display_model_results(train_mse, train_r2, test_mse, test_r2, cross_val_rmse, cross_val_r2, model_description=\"Linear Regression (Log Transformed / No Scaling)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Linear Regression: MinMax & Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LINEAR REGRESSION (STD SCALING / NO LOG TRANS.):\n",
      "Training MSE: 2184176.2584\n",
      "Training R^2: 0.3909\n",
      "Test MSE: 3737592.9884\n",
      "Test R^2: 0.3870\n",
      "Cross-Validation RMSE: 1547.5232 ± 265.7279\n",
      "Cross-Validation R^2: 0.2609 ± 0.2117\n",
      "========================================\n",
      "Results for LINEAR REGRESSION (MINMAX SCALING / NO LOG TRANS.):\n",
      "Training MSE: 2184176.2584\n",
      "Training R^2: 0.3909\n",
      "Test MSE: 3737592.9884\n",
      "Test R^2: 0.3870\n",
      "Cross-Validation RMSE: 1547.5232 ± 265.7279\n",
      "Cross-Validation R^2: 0.2609 ± 0.2117\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# define features as `X` and target variable as `y`   \n",
    "X = maize_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = maize_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# standard scaling, linear regression\n",
    "linear_pipeline_std_scaling = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# minmax scaling, linear regression\n",
    "linear_pipeline_minmax_scaling = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# instantiate cross validation\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "evaluate_pipeline(linear_pipeline_std_scaling, X_train, y_train, X_test, y_test, model_description=\"Linear Regression (Std Scaling / No Log Trans.)\", cv=cv)\n",
    "evaluate_pipeline(linear_pipeline_minmax_scaling, X_train, y_train, X_test, y_test, model_description=\"Linear Regression (MinMax Scaling / No Log Trans.)\", cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMax & Standard Scaling (Log Transformed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LINEAR REGRESSION: LOG TRANSFORMED (STD SCALING):\n",
      "Training MSE: 0.0159\n",
      "Training R^2: 0.3242\n",
      "Test MSE: 0.0234\n",
      "Test R^2: 0.3933\n",
      "Cross-Validation RMSE: 0.1319 ± 0.0262\n",
      "Cross-Validation R^2: 0.1849 ± 0.2005\n",
      "========================================\n",
      "Results for LINEAR REGRESSION: LOG TRANSFORMED (MINMAX SCALING):\n",
      "Training MSE: 0.0159\n",
      "Training R^2: 0.3242\n",
      "Test MSE: 0.0234\n",
      "Test R^2: 0.3933\n",
      "Cross-Validation RMSE: 0.1319 ± 0.0262\n",
      "Cross-Validation R^2: 0.1849 ± 0.2005\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# define features as `X` and target variable as `y`   \n",
    "X = log_transformed_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = log_transformed_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# instantiate cross validation\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# standard scaling, linear regression\n",
    "linear_pipeline_std_scaling = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# minmax scaling, linear regression\n",
    "linear_pipeline_minmax_scaling = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "evaluate_pipeline(linear_pipeline_std_scaling, X_train, y_train, X_test, y_test, model_description=\"Linear Regression: Log Transformed (Std Scaling)\", cv=cv)\n",
    "evaluate_pipeline(linear_pipeline_minmax_scaling, X_train, y_train, X_test, y_test, model_description=\"Linear Regression: Log Transformed (MinMax Scaling)\", cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Ridge Regression \n",
    "<br> Log transformation with two feature scaling techniques: standard and min-max \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RIDGE REGRESSION: LOG TRANSFORMED (STD SCALING):\n",
      "Training MSE: 0.0159\n",
      "Training R^2: 0.3242\n",
      "Test MSE: 0.0235\n",
      "Test R^2: 0.3914\n",
      "Cross-Validation RMSE: 0.1318 ± 0.0263\n",
      "Cross-Validation R^2: 0.1868 ± 0.1979\n",
      "========================================\n",
      "Results for RIDGE REGRESSION: LOG TRANSFORMED (MINMAX SCALING):\n",
      "Training MSE: 0.0161\n",
      "Training R^2: 0.3168\n",
      "Test MSE: 0.0246\n",
      "Test R^2: 0.3621\n",
      "Cross-Validation RMSE: 0.1312 ± 0.0268\n",
      "Cross-Validation R^2: 0.2007 ± 0.1693\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# define features as `X` and target variable as `y`   \n",
    "X = log_transformed_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = log_transformed_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# instantiate cross validation\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# standard scaling, linear regression\n",
    "ridge_pipeline_std_scaling = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "# minmax scaling, linear regression\n",
    "ridge_pipeline_minmax_scaling = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', Ridge())\n",
    "])\n",
    "\n",
    "evaluate_pipeline(ridge_pipeline_std_scaling, X_train, y_train, X_test, y_test, model_description=\"Ridge Regression: Log Transformed (Std Scaling)\", cv=cv)\n",
    "evaluate_pipeline(ridge_pipeline_minmax_scaling, X_train, y_train, X_test, y_test, model_description=\"Ridge Regression: Log Transformed (MinMax Scaling)\", cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Random Forest \n",
    "Log transformed data with two different scaling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for RANDOM FOREST: STD SCALING:\n",
      "Training MSE: 0.0024\n",
      "Training R^2: 0.8988\n",
      "Test MSE: 0.0195\n",
      "Test R^2: 0.4945\n",
      "Cross-Validation RMSE: 0.1204 ± 0.0146\n",
      "Cross-Validation R^2: 0.3265 ± 0.1382\n",
      "========================================\n",
      "Results for RANDOM FOREST: MINMAX SCALING:\n",
      "Training MSE: 0.0024\n",
      "Training R^2: 0.8992\n",
      "Test MSE: 0.0182\n",
      "Test R^2: 0.5283\n",
      "Cross-Validation RMSE: 0.1163 ± 0.0146\n",
      "Cross-Validation R^2: 0.3185 ± 0.1551\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# define features as `X` and target variable as `y`   \n",
    "y = log_transformed_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "X = log_transformed_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# instantiate cross validation\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# apply RandomForest with standard scaling\n",
    "random_forest_std_scaler_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# apply RandomForest with min max scaling\n",
    "random_forest_minmax_scaler_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "evaluate_pipeline(random_forest_std_scaler_pipeline, X_train, y_train, X_test, y_test, model_description=\"Random Forest: Std Scaling\", cv=cv)\n",
    "evaluate_pipeline(random_forest_minmax_scaler_pipeline, X_train, y_train, X_test, y_test, model_description=\"Random Forest: MinMax Scaling\", cv=cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Random Forest - Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters found by RandomizedSearchCV: {'model__n_estimators': 200, 'model__min_samples_split': 10, 'model__min_samples_leaf': 2, 'model__max_features': None, 'model__max_depth': None}\n",
      "\n",
      "Results for TUNED RANDOM FOREST REGRESSION WITH STANDARD SCALING:\n",
      "Training MSE: 0.0077\n",
      "Training R^2: 0.6737\n",
      "Test MSE: 0.0188\n",
      "Test R^2: 0.5145\n",
      "Cross-Validation RMSE: 0.1174 ± 0.0148\n",
      "Cross-Validation R^2: 0.3464 ± 0.1162\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define features as `X` and target variable as `y`\n",
    "X = log_transformed_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = log_transformed_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [10, 20, 30, None],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4],\n",
    "    'model__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Create a pipeline that includes standard scaling and the random forest model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Initialize RandomizedSearchCV with the pipeline\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist, \n",
    "                                   n_iter=50, cv=5, n_jobs=-1, scoring='neg_mean_squared_error', \n",
    "                                   random_state=42, verbose=2)\n",
    "\n",
    "# Perform the random search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters found by RandomizedSearchCV: {random_search.best_params_}\\n\")\n",
    "\n",
    "# Get the best estimator (pipeline with the best model)\n",
    "best_pipeline = random_search.best_estimator_\n",
    "\n",
    "# Calculate training MSE and R^2\n",
    "y_train_pred = best_pipeline.predict(X_train)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate test MSE and R^2\n",
    "y_test_pred = best_pipeline.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "cross_val_mse = cross_val_score(best_pipeline, X_train, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "cross_val_rmse = np.sqrt(-cross_val_mse)\n",
    "\n",
    "# Cross-validation R^2 score\n",
    "cross_val_r2 = cross_val_score(best_pipeline, X_train, y_train, cv=cv, scoring='r2')\n",
    "\n",
    "# Display model results\n",
    "display_model_results(train_mse, train_r2, test_mse, test_r2, cross_val_rmse, cross_val_r2, model_description=\"Tuned Random Forest Regression with Standard Scaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Gradient Boosting Regression\n",
    "Log transformed, looking at two scaling techniques (std and minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for GRADIENT BOOSTING: STD SCALING:\n",
      "Training MSE: 0.0006\n",
      "Training R^2: 0.9758\n",
      "Test MSE: 0.0197\n",
      "Test R^2: 0.4903\n",
      "Cross-Validation RMSE: 0.1331 ± 0.0194\n",
      "Cross-Validation R^2: 0.1050 ± 0.3266\n",
      "========================================\n",
      "Results for GRADIENT BOOSTING: MINMAX SCALING:\n",
      "Training MSE: 0.0006\n",
      "Training R^2: 0.9758\n",
      "Test MSE: 0.0197\n",
      "Test R^2: 0.4904\n",
      "Cross-Validation RMSE: 0.1332 ± 0.0186\n",
      "Cross-Validation R^2: 0.1014 ± 0.3373\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# define features as `X` and target variable as `y`   \n",
    "X = log_transformed_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = log_transformed_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# instantiate cross validation\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# apply RandomForest with standard scaling\n",
    "gradient_boosting_std_scaler_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('model', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "# apply RandomForest with min max scaling\n",
    "gradient_boosting_minmax_scaler_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "evaluate_pipeline(gradient_boosting_std_scaler_pipeline, X_train, y_train, X_test, y_test, model_description=\"Gradient Boosting: Std Scaling\", cv=cv)\n",
    "evaluate_pipeline(gradient_boosting_minmax_scaler_pipeline, X_train, y_train, X_test, y_test, model_description=\"Gradient Boosting: MinMax Scaling\", cv=cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 SVR with RBF & Poly kernel and scaling comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVR (RBF KERNEL): STD SCALING:\n",
      "Training MSE: 0.0107\n",
      "Training R^2: 0.5451\n",
      "Test MSE: 0.0221\n",
      "Test R^2: 0.4270\n",
      "Cross-Validation RMSE: 0.1362 ± 0.0249\n",
      "Cross-Validation R^2: 0.0994 ± 0.2982\n",
      "========================================\n",
      "Results for SVR (RBF KERNEL): MINMAX SCALING:\n",
      "Training MSE: 0.0112\n",
      "Training R^2: 0.5225\n",
      "Test MSE: 0.0219\n",
      "Test R^2: 0.4319\n",
      "Cross-Validation RMSE: 0.1282 ± 0.0221\n",
      "Cross-Validation R^2: 0.2045 ± 0.2458\n",
      "========================================\n",
      "Results for SVR (POLY KERNEL): STD SCALING:\n",
      "Training MSE: 0.0159\n",
      "Training R^2: 0.3258\n",
      "Test MSE: 0.0249\n",
      "Test R^2: 0.3560\n",
      "Cross-Validation RMSE: 0.1790 ± 0.0794\n",
      "Cross-Validation R^2: -0.7383 ± 1.6082\n",
      "========================================\n",
      "Results for SVR (POLY KERNEL): MINMAX SCALING:\n",
      "Training MSE: 0.0128\n",
      "Training R^2: 0.4574\n",
      "Test MSE: 0.0281\n",
      "Test R^2: 0.2715\n",
      "Cross-Validation RMSE: 0.1282 ± 0.0235\n",
      "Cross-Validation R^2: 0.2034 ± 0.2722\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# define features as `X` and target variable as `y`   \n",
    "X = log_transformed_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = log_transformed_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# instantiate cross validation\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# apply SVR (RBF Kernel) with standard scaling\n",
    "svr_std_scaler_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('model', SVR(kernel='rbf'))\n",
    "])\n",
    "\n",
    "# apply SVR (RBF Kernel) with min max scaling\n",
    "svr_minmax_scaler_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', SVR(kernel='rbf'))\n",
    "])\n",
    "\n",
    "# apply SVR (Poly Kernel) with standard scaling\n",
    "svr_poly_std_scaler_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('model', SVR(kernel='poly'))\n",
    "])\n",
    "\n",
    "# apply SVR (Poly Kernel) with min max scaling\n",
    "svr_poly_minmax_scaler_pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', SVR(kernel='poly'))\n",
    "])\n",
    "\n",
    "evaluate_pipeline(svr_std_scaler_pipeline, X_train, y_train, X_test, y_test, model_description=\"SVR (RBF Kernel): Std Scaling\", cv=cv)\n",
    "evaluate_pipeline(svr_minmax_scaler_pipeline, X_train, y_train, X_test, y_test, model_description=\"SVR (RBF Kernel): MinMax Scaling\", cv=cv)\n",
    "evaluate_pipeline(svr_poly_std_scaler_pipeline, X_train, y_train, X_test, y_test, model_description=\"SVR (Poly Kernel): Std Scaling\", cv=cv)\n",
    "evaluate_pipeline(svr_poly_minmax_scaler_pipeline, X_train, y_train, X_test, y_test, model_description=\"SVR (Poly Kernel): MinMax Scaling\", cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Summary\n",
    "\n",
    "| Model                     | Preprocessing            | Feature Scaling | Target Scaling | Train MSE  | Test MSE  | Train R² | Test R² | CV RMSE   | CV RMSE STD | CV R²   | CV R² STD |\n",
    "|---------------------------|--------------------------|-----------------|----------------|------------|-----------|----------|---------|------------|-------------|---------|-----------|\n",
    "| Linear Regression          | None                     | None            | None           | 2184176.258 | 3737592.988 | 0.3909   | 0.387   | 1547.5232 | 265.7279    | 0.2609  | 0.2117    |\n",
    "| Linear Regression          | None                     | Standard        | None           | 2184176.258 | 3737592.988 | 0.3909   | 0.387   | 1547.5232 | 265.7279    | 0.2609  | 0.2117    |\n",
    "| Linear Regression          | None                     | MinMax          | None           | 2184176.258 | 3737592.988 | 0.3909   | 0.387   | 1547.5232 | 265.7279    | 0.2609  | 0.2117    |\n",
    "| Linear Regression          | Log transformation       | Standard        | None           | 0.0159     | 0.0234    | 0.3242   | 0.3933  | 0.1319    | 0.0262      | 0.1849  | 0.2005    |\n",
    "| Linear Regression          | Log transformation       | MinMax          | None           | 0.0159     | 0.0234    | 0.3242   | 0.3933  | 0.1319    | 0.0262      | 0.1849  | 0.2005    |\n",
    "| Ridge Regression           | Log transformation       | Standard        | None           | 0.0159     | 0.0235    | 0.3242   | 0.3914  | 0.1318    | 0.0263      | 0.1868  | 0.1979    |\n",
    "| Ridge Regression           | Log transformation       | MinMax          | None           | 0.0161     | 0.0246    | 0.3168   | 0.3621  | 0.1312    | 0.0268      | 0.2007  | 0.1693    |\n",
    "| Random Forest              | Log transformation       | Standard        | None           | 0.0024     | 0.0195    | 0.8988   | 0.4945  | 0.1204    | 0.0146      | 0.3265  | 0.1382    |\n",
    "| Random Forest              | Log transformation       | MinMax          | None           | 0.0024     | 0.0182    | 0.8992   | 0.5283  | 0.1163    | 0.0146      | 0.3185  | 0.1551    |\n",
    "| Random Forest Tuned        | Log transformation       | Standard        | None           | 0.0077     | 0.0188    | 0.6737   | 0.5145  | 0.1174    | 0.0148      | 0.3464  | 0.1162    |\n",
    "| *Random Forest RFE_3        | Log transformation       | None            | None           | 0.0179     | 0.0179    | 0.5364   | 0.5364  | 0.1202    | 0.0122      | 0.3068  | 0.136     |\n",
    "| *Random Forest RFE_5        | Log transformation       | None            | None           | 0.0197     | 0.0197    | 0.4905   | 0.4905  | 0.1191    | 0.0095      | 0.3094  | 0.1636    |\n",
    "| Gradient Boosting          | Log transformation       | Standard        | None           | 0.0006     | 0.0197    | 0.9758   | 0.4903  | 0.1331    | 0.0194      | 0.105   | 0.3266    |\n",
    "| Gradient Boosting          | Log transformation       | MinMax          | None           | 0.0006     | 0.0197    | 0.9758   | 0.4904  | 0.1332    | 0.0186      | 0.1014  | 0.3373    |\n",
    "| SVR with RBF kernel        | Log transformation       | Standard        | None           | 0.0107     | 0.0221    | 0.5451   | 0.427   | 0.1362    | 0.0249      | 0.0994  | 0.2982    |\n",
    "| SVR with RBF kernel        | Log transformation       | MinMax          | None           | 0.0112     | 0.0219    | 0.5225   | 0.4319  | 0.1282    | 0.0221      | 0.2045  | 0.2458    |\n",
    "| SVR with poly kernel       | Log transformation       | Standard        | None           | 0.0159     | 0.0249    | 0.3258   | 0.356   | 0.179     | 0.0794      | -0.7383 | 1.6082    |\n",
    "| SVR with poly kernel       | Log transformation       | MinMax          | None           | 0.0128     | 0.0281    | 0.4574   | 0.2715  | 0.1282    | 0.0235      | 0.2034  | 0.2722    |\n",
    "\n",
    "(*) See section after next steps / future work for this code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps / Future Work\n",
    "- visualize modeling results \n",
    "- finish paper \n",
    "- continue exploring feature egineering: started with Recursive Feature Elimination for RandomForest (shown below) but need to clean up code and read more on this...\n",
    "- future work: investigate if scaling target affects model performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Max_LAI', 'Annual_ETc mm', 'Trt_code', 'Plant density plants ha-1',\n",
      "       'HI'],\n",
      "      dtype='object')\n",
      "Results for RANDOM FOREST REGRESSION WITH RFE:\n",
      "Training MSE: 0.0197\n",
      "Training R^2: 0.4905\n",
      "Test MSE: 0.0197\n",
      "Test R^2: 0.4905\n",
      "Cross-Validation RMSE: 0.1191 ± 0.0095\n",
      "Cross-Validation R^2: 0.3094 ± 0.1636\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# we want the log transformed data but with all cols to see if RFE can find better features and improve the model\n",
    "log_data_all_cols = apply_log_transform_with_constant(maize_data)\n",
    "\n",
    "X = log_data_all_cols.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = log_data_all_cols['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize simple linear reg. model for RFE \n",
    "model = LinearRegression()\n",
    "\n",
    "# apply RFE to select top features\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)  \n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# display selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the selected features\n",
    "rf_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = rf_model.predict(X_test_rfe)\n",
    "\n",
    "# Evaluate the model\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "cross_val_mse = cross_val_score(rf_model, X_train_rfe, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "cross_val_rmse = np.sqrt(-cross_val_mse)\n",
    "\n",
    "# Cross-validation R^2 score\n",
    "cross_val_r2 = cross_val_score(rf_model, X_train_rfe, y_train, cv=cv, scoring='r2')\n",
    "\n",
    "# get results\n",
    "display_model_results(test_mse, test_r2, test_mse, test_r2, cross_val_rmse, cross_val_r2, model_description=\"Random Forest Regression with RFE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['Trt_code', 'Plant density plants ha-1', 'Max_LAI'], dtype='object')\n",
      "Results for RANDOM FOREST REGRESSION WITH RFE:\n",
      "Training MSE: 0.0179\n",
      "Training R^2: 0.5364\n",
      "Test MSE: 0.0179\n",
      "Test R^2: 0.5364\n",
      "Cross-Validation RMSE: 0.1202 ± 0.0122\n",
      "Cross-Validation R^2: 0.3068 ± 0.1360\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# what if we limit it to the features we identified ? can we get better results?\n",
    "log_data_trimmed = apply_log_transform_with_constant(maize_model_data)\n",
    "\n",
    "X = log_data_trimmed.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = log_data_trimmed['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize simple linear reg. model for RFE \n",
    "model = LinearRegression()\n",
    "\n",
    "# apply RFE to select top features\n",
    "rfe = RFE(estimator=model, n_features_to_select=3)  \n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# display selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the selected features\n",
    "rf_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = rf_model.predict(X_test_rfe)\n",
    "\n",
    "# Evaluate the model\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Perform cross-validation on the training set\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "cross_val_mse = cross_val_score(rf_model, X_train_rfe, y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "cross_val_rmse = np.sqrt(-cross_val_mse)\n",
    "\n",
    "# Cross-validation R^2 score\n",
    "cross_val_r2 = cross_val_score(rf_model, X_train_rfe, y_train, cv=cv, scoring='r2')\n",
    "\n",
    "# get results\n",
    "display_model_results(test_mse, test_r2, test_mse, test_r2, cross_val_rmse, cross_val_r2, model_description=\"Random Forest Regression with RFE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY = 'cleaned_annual_data.csv'\n",
    "maize_data = pd.read_csv(FILE)\n",
    "maize_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "\n",
    "\n",
    "| **Trt Code** | **Irr Treatment (late veg/grain filling)** |\n",
    "|--------------|-------------------|\n",
    "| 1            | 100/100           |\n",
    "| 2            | 100/50            |\n",
    "| 3            | 80/80             |\n",
    "| 4            | 80/65             |\n",
    "| 5            | 80/50             |\n",
    "| 6            | 80/40             |\n",
    "| 7            | 65/80             |\n",
    "| 8            | 65/65             |\n",
    "| 9            | 65/50             |\n",
    "| 10           | 65/40             |\n",
    "| 11           | 50/50             |\n",
    "| 12           | 40/40             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at model coefficients -- Ordered from most to least significant impact on grain yield: Treatment Code, Max Leaf Area Index, and Plant Density \n",
    "\n",
    "The coefficients for this model tell us:\n",
    "- `Trt_code`: Strong negative relationship with grain yield. For every 1 unit increase in `Treatment_code` (which reduces water usage), the grain yield is expected to decrease by ~338.83 Kg / h1 units. (~746.99 lbs)\n",
    "- `Plant density plants ha-1`: Very weak positive relationship with grain yield. The impact of plant density is minimal. Every 1 unit increase in this coef, grain yield should increase by 0.03 Kg / h1 units (~.07 lbs) \n",
    "- `Max_LAI`: Strong positive relationship with grain yield. This feature has a significant impact on grain yield. For every 1 unit increase in max leaf area, grain yield should increase by 527.54 Kg / h1 units (~1,163.03)\n",
    "\n",
    "_Note: 1 hectare = 2.47 acres, or 107,639 square feet_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trt_code</th>\n",
       "      <td>-338.829080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plant density plants ha-1</th>\n",
       "      <td>0.036397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_LAI</th>\n",
       "      <td>527.542289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Coefficients\n",
       "Trt_code                    -338.829080\n",
       "Plant density plants ha-1      0.036397\n",
       "Max_LAI                      527.542289"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Define features as `X` and target variable (Grain Yield) as `y`\n",
    "X = maize_model_data.drop(columns=['Grain Yield_15.5%mc_Kg ha-1'])\n",
    "y = maize_model_data['Grain Yield_15.5%mc_Kg ha-1']\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize the model\n",
    "linear_regression_model = LinearRegression()\n",
    "\n",
    "# train the model on non-transformed data\n",
    "linear_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Extract and display the coefficients\n",
    "coefs = pd.DataFrame(\n",
    "linear_regression_model.coef_,\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names\n",
    ")\n",
    "\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "Treatment code (watering) is most important while plant density is the least important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get feature importance from Random Forest model\n",
    "# feature_importances = random_forest_model.feature_importances_\n",
    "# features = X.columns\n",
    "\n",
    "# # Create a DataFrame to display feature importances\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'Feature': features,\n",
    "#     'Importance': feature_importances\n",
    "# }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# importance_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PandasPractice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
